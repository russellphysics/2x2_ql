{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "909dced5-ab03-4621-95c5-849372095c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import json\n",
    "import sklearn.decomposition as dcomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91ebce3f-eef2-444b-bf01-2837497f5f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_tolerance=1.0 # cm\n",
    "residual_threshold=2.0 # cm\n",
    "module_iogroups={0:[1,2], 1:[3,4], 2:[5,6], 3:[7,8]}\n",
    "x_outer_extent=63.930999755859375\n",
    "x_inner_extent=3.069000005722046\n",
    "y_upper_extent=62.076\n",
    "y_lower_extent=-62.076\n",
    "z_outer_extent=64.538\n",
    "z_inner_extent=2.4620001\n",
    "drift_distance=30.\n",
    "\n",
    "data_tpc_xrange={8:[-1*x_outer_extent,(-1*x_outer_extent)+drift_distance], 6:[-1*x_outer_extent,(-1*x_outer_extent)+drift_distance],\n",
    "            7:[(-1*x_inner_extent)-drift_distance,-1*x_inner_extent], 5:[(-1*x_inner_extent)-drift_distance,-1*x_inner_extent],\n",
    "            4:[x_inner_extent,x_inner_extent+drift_distance], 2:[x_inner_extent,x_inner_extent+drift_distance],\n",
    "            3:[x_outer_extent-drift_distance, x_outer_extent], 1:[x_outer_extent-drift_distance, x_outer_extent]}\n",
    "\n",
    "mc_tpc_xrange={7:[-1*x_outer_extent,(-1*x_outer_extent)+drift_distance], 5:[-1*x_outer_extent,(-1*x_outer_extent)+drift_distance],\n",
    "            8:[(-1*x_inner_extent)-drift_distance,-1*x_inner_extent], 6:[(-1*x_inner_extent)-drift_distance,-1*x_inner_extent],\n",
    "            3:[x_inner_extent,x_inner_extent+drift_distance], 1:[x_inner_extent,x_inner_extent+drift_distance],\n",
    "            4:[x_outer_extent-drift_distance, x_outer_extent], 2:[x_outer_extent-drift_distance, x_outer_extent]}\n",
    "tpc_zrange={8:[-1*z_outer_extent,-1*z_inner_extent], 6:[z_inner_extent,z_outer_extent],\n",
    "            7:[-1*z_outer_extent,-1*z_inner_extent], 5:[z_inner_extent,z_outer_extent],\n",
    "            4:[-1*z_outer_extent,-1*z_inner_extent], 2:[z_inner_extent,z_outer_extent],\n",
    "            3:[-1*z_outer_extent,-1*z_inner_extent], 1:[z_inner_extent,z_outer_extent]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e3f23-3231-4bff-b178-bda0e473554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filedir='/global/cfs/cdirs/dune/www/data/2x2/simulation/productions/MiniRun6.2_1E19_RHC/MiniRun6.2_1E19_RHC.flow/FLOW/0000000/'\n",
    "run_no=[]\n",
    "scan_coverage(filedir, run_no, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e1baeb-4060-43cd-9e09-6b2df72036fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 18/263 [01:39<18:08,  4.44s/it]"
     ]
    }
   ],
   "source": [
    "filedir='/global/cfs/cdirs/dune/www/data/2x2/nearline/flowed_charge/REFLOW/v4/beam/july10_2024/nominal_hv/'\n",
    "run_no=['0050018']\n",
    "scan_coverage(filedir, run_no, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54f919b-6aa5-4394-9fad-ea1bb2d51aff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def scan_coverage(filedir, run_no, is_mc, flag=False):\n",
    "    for filename in tqdm(glob.glob(filedir+'*.hdf5')):\n",
    "        if is_mc==False:\n",
    "            file_run_no = filename.split(\"/\")[-1].split(\"-\")[1] \n",
    "            if file_run_no not in run_no: continue\n",
    "            dt_string = filename.split(\"/\")[-1].split(\"-\")[-1].split(\"_CDT\")[0]\n",
    "        if is_mc==True:\n",
    "            if flag==False: # dedicated electron lifetime sample\n",
    "                file_run_no=filename.split(\"/\")[6].split(\"_\")[-1]\n",
    "                if file_run_no not in run_no: continue\n",
    "                dt_string=filename.split(\"/\")[-1].split(\".\")[2]\n",
    "            if flag==True: # regular MC production sample\n",
    "                file_run_no='minirun6_2'\n",
    "                dt_string=filename.split(\"/\")[-1].split(\".\")[-3]\n",
    "              \n",
    "        try: f = h5py.File(filename, 'r')\n",
    "        except: continue\n",
    "        try: ext_full = f['charge/ext_trigs/data']\n",
    "        except: continue\n",
    "        try: hits_full = f['charge/calib_prompt_hits/data']\n",
    "        except: continue\n",
    "        \n",
    "        exts_ref = f['charge/events/ref/charge/ext_trigs/ref']\n",
    "        ext_region = f['charge/events/ref/charge/ext_trigs/ref_region']        \n",
    "        hits_ref = f['charge/events/ref/charge/calib_prompt_hits/ref']\n",
    "        hits_region = f['charge/events/ref/charge/calib_prompt_hits/ref_region']\n",
    "\n",
    "        out = {}\n",
    "        event_ids=np.unique(f['charge/events/data']['id'])\n",
    "        for event_id in event_ids:\n",
    "\n",
    "            ext_ref = exts_ref[ext_region[event_id,'start']:ext_region[event_id,'stop']]\n",
    "            if ext_ref.shape[0]==0: \n",
    "                ext_type=-1\n",
    "                ext_iog=-1\n",
    "            else:\n",
    "                ext_ref = np.sort(ext_ref[ext_ref[:,0] == event_id, 1])\n",
    "                ext_trigs = ext_full[ext_ref]\n",
    "                ext_type=int(ext_trigs['type'][0])\n",
    "                ext_iog=int(ext_trigs['iogroup'][0])\n",
    "            \n",
    "            hit_ref = hits_ref[hits_region[event_id,'start']:hits_region[event_id,'stop']]\n",
    "            hit_ref = np.sort(hit_ref[hit_ref[:,0] == event_id, 1])\n",
    "            hits = hits_full[hit_ref]\n",
    "            nh=len(hits)\n",
    "            if nh<50: continue\n",
    "\n",
    "            for tpc_id in range(1,9,1):\n",
    "                tpc_hits=hits[hits['io_group']==tpc_id]\n",
    "                if is_mc==False:\n",
    "                    mask=ma.masked_inside(tpc_hits['x'], data_tpc_xrange[tpc_id][0], data_tpc_xrange[tpc_id][1])                 \n",
    "                    x=tpc_hits['x'][mask.mask]\n",
    "                    y=tpc_hits['y'][mask.mask]\n",
    "                    z=tpc_hits['z'][mask.mask]\n",
    "                else:             \n",
    "                    x=tpc_hits['x']\n",
    "                    y=tpc_hits['y']\n",
    "                    z=tpc_hits['z']\n",
    "                nx=len(x)\n",
    "                if nx<50 or nx>2000: continue\n",
    "\n",
    "                if is_mc==False:\n",
    "                    xnan=np.isnan(x); ynan=np.isnan(y); znan=np.isnan(z)\n",
    "                    if np.any(xnan) or np.any(ynan) or np.any(znan): continue\n",
    "\n",
    "                x_miss_frac, y_miss_frac, z_miss_frac = missing_extent_coverage(tpc_id, x,y,z, is_mc)\n",
    "                orientation='x'; miss_frac=x_miss_frac\n",
    "                if y_miss_frac<x_miss_frac:\n",
    "                    orientation='y'; miss_frac=y_miss_frac\n",
    "                    if z_miss_frac<y_miss_frac: orientation='z'; miss_frac=z_miss_frac\n",
    "                if z_miss_frac<x_miss_frac:\n",
    "                    orientation='z'; miss_frac=z_miss_frac\n",
    "                    if y_miss_frac<z_miss_frac: orientation='y'; miss_frac=y_miss_frac\n",
    "\n",
    "                abort = tpc_dimension_extreme(tpc_id, orientation, x, y, z, is_mc)\n",
    "                if abort==True: continue\n",
    "                \n",
    "                xyz=np.concatenate((np.expand_dims(x, axis=-1), np.expand_dims(y, axis=-1), np.expand_dims(z, axis=-1),), axis=-1)\n",
    "                centroid = np.mean(xyz, axis=0)\n",
    "                pca = dcomp.PCA(n_components=1).fit(xyz-centroid)\n",
    "                axis = pca.components_[0] / np.linalg.norm(pca.components_[0])\n",
    "                if axis[1]>0: axis=-axis\n",
    "                s=np.dot((xyz-centroid), axis)\n",
    "                xyz_min, xyz_max = np.amin(xyz, axis=0), np.amax(xyz, axis=0)\n",
    "                r_max = np.clip(centroid + axis * np.max(s), xyz_min, xyz_max)\n",
    "                r_min = np.clip(centroid + axis * np.min(s), xyz_min, xyz_max)\n",
    "                track_length=np.linalg.norm(r_max - r_min) # cm\n",
    "                \n",
    "                theta = np.arctan2(np.linalg.norm(axis[:2]), axis[-1]) # w.r.t. z-axis \n",
    "                phi = np.arctan2(axis[1], axis[0]) # about z-axis\n",
    "\n",
    "                res=np.abs(xyz-(centroid+np.outer(s, axis)))\n",
    "                count_distant=0\n",
    "                for r in res:\n",
    "                    residual_distance = np.sqrt((r[0]**2) + (r[1]**2) + (r[2]**2))\n",
    "                    if residual_distance>residual_threshold: count_distant+=1\n",
    "                residual_fraction = count_distant / len(res)\n",
    "\n",
    "                if orientation not in out.keys(): out[orientation]={}       \n",
    "                if str(tpc_id) not in out[orientation].keys(): out[orientation][str(tpc_id)]={}\n",
    "                if str(event_id) not in out[orientation][str(tpc_id)].keys(): \n",
    "                    out[orientation][str(tpc_id)][str(event_id)]=[residual_fraction, miss_frac, theta, phi, track_length, ext_type, ext_iog]\n",
    "        \n",
    "        if len(out.keys())!=0:\n",
    "            if is_mc==True:\n",
    "                with open('tgm_coverage_mc_'+file_run_no+'-'+dt_string+'.json','w') as outfile: json.dump(out, outfile, indent=4)     \n",
    "            else: \n",
    "                with open('tgm_coverage_'+file_run_no+'-'+dt_string+'.json','w') as outfile: json.dump(out, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17d7997b-2987-4765-8080-4699ac7ef971",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def tpc_dimension_extreme(tpc_id, orientation, x, y, z, is_mc):\n",
    "    abort=False\n",
    "    if orientation=='x':\n",
    "        min_x = min(x); max_x = max(x)\n",
    "        if is_mc==False: tpc_xrange=data_tpc_xrange\n",
    "        if is_mc==True: tpc_xrange=mc_tpc_xrange\n",
    "        if tpc_id in [1,2,3,4]:\n",
    "            if abs(max_x-tpc_xrange[tpc_id][1])>boundary_tolerance: abort=True\n",
    "            if abs(min_x-tpc_xrange[tpc_id][0])>boundary_tolerance: abort=True\n",
    "        if tpc_id in [5,6,7,8]:\n",
    "            if abs(abs(tpc_xrange[tpc_id][1])-abs(max_x))>boundary_tolerance: abort=True\n",
    "            if abs(abs(tpc_xrange[tpc_id][0])-abs(min_x))>boundary_tolerance: abort=True\n",
    "    if orientation=='y':\n",
    "        min_y = min(y); max_y = max(y)\n",
    "        if min_y>0: abort=True\n",
    "        if max_y<0: abort=True\n",
    "        if y_upper_extent-max_y>boundary_tolerance: abort=True\n",
    "        if abs(abs(y_lower_extent)-abs(min_y))>boundary_tolerance: abort=True\n",
    "    if orientation=='z':\n",
    "        min_z = min(z); max_z = max(z)\n",
    "        if tpc_id in [1,2,5,6]:\n",
    "            if abs(max_z-tpc_zrange[tpc_id][1])>boundary_tolerance: abort=True\n",
    "            if abs(min_z-tpc_zrange[tpc_id][0])>boundary_tolerance: abort=True\n",
    "        if tpc_id in [3,4,7,8]:\n",
    "            if abs(abs(tpc_zrange[tpc_id][1])-abs(max_z))>boundary_tolerance: abort=True\n",
    "            if abs(abs(tpc_zrange[tpc_id][0])-abs(min_z))>boundary_tolerance: abort=True\n",
    "    return abort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe96036a-9f53-4ccb-8855-bbd65f564c4a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def missing_extent_coverage(tpc_id, x, y, z, is_mc):\n",
    "    if is_mc==True:\n",
    "        x_vals, x_bin_edges = np.histogram(x, bins=np.linspace(mc_tpc_xrange[tpc_id][0], mc_tpc_xrange[tpc_id][1], int(mc_tpc_xrange[tpc_id][1]-mc_tpc_xrange[tpc_id][0])+1))\n",
    "        absent_x=0\n",
    "        for v in x_vals:\n",
    "            if v==0: absent_x+=1\n",
    "        x_missing_fraction = absent_x / int(mc_tpc_xrange[tpc_id][1]-mc_tpc_xrange[tpc_id][0])\n",
    "        \n",
    "    if is_mc==False:\n",
    "        x_vals, x_bin_edges = np.histogram(x, bins=np.linspace(data_tpc_xrange[tpc_id][0], data_tpc_xrange[tpc_id][1], int(data_tpc_xrange[tpc_id][1]-data_tpc_xrange[tpc_id][0])+1))\n",
    "        absent_x=0\n",
    "        for v in x_vals:\n",
    "            if v==0: absent_x+=1\n",
    "        x_missing_fraction = absent_x / int(data_tpc_xrange[tpc_id][1]-data_tpc_xrange[tpc_id][0])\n",
    "\n",
    "    y_vals, y_bin_edges = np.histogram(y, bins=np.linspace(y_lower_extent, y_upper_extent, int(y_upper_extent-y_lower_extent)+1))\n",
    "    absent_y=0\n",
    "    for v in y_vals:\n",
    "        if v==0: absent_y+=1\n",
    "    y_missing_fraction = absent_y / int(y_upper_extent-y_lower_extent)\n",
    "\n",
    "    z_vals, z_bin_edges = np.histogram(z, bins=np.linspace(tpc_zrange[tpc_id][0], tpc_zrange[tpc_id][1], int(tpc_zrange[tpc_id][1]-tpc_zrange[tpc_id][0])+1))\n",
    "    absent_z=0\n",
    "    for v in z_vals:\n",
    "        if v==0: absent_z+=1\n",
    "    z_missing_fraction = absent_z / int(tpc_zrange[tpc_id][1]-tpc_zrange[tpc_id][0])\n",
    "\n",
    "    return x_missing_fraction, y_missing_fraction, z_missing_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c98d50-f2ad-4066-94b4-fab88ff461f5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def report_tpc_dimensions(filedir, dimension):\n",
    "    for filename in tqdm(glob.glob(filedir+'*.hdf5')):\n",
    "        f = h5py.File(filename, 'r')\n",
    "        for iog in range(1,9,1): \n",
    "            module=int((iog-1)/2)\n",
    "            tpc=(iog-2)%2\n",
    "            print(f['geometry_info'].attrs['module_RO_bounds'][module][tpc][dimension])\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
